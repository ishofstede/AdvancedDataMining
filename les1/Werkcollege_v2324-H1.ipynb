{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deel I. Machine learning\n",
    "\n",
    "## Hoofdstuk 1. Het perceptron\n",
    "\n",
    "1. [Inleiding](#Inleiding)\n",
    "2. [Het perceptron](#Het_perceptron)\n",
    "3. [Lineaire regressie](#Lineaire_regressie)\n",
    "\n",
    "### <a id='Inleiding'>Inleiding</a>\n",
    "\n",
    "Dit is het Jupyter Notebook behorende bij hoofdstuk 1 van het vak *Advanced Datamining* (BFVH4DMN2). Op BlackBoard tref je eveneens een module `data.py` aan die diverse functies bevat die helpen bij het genereren en het visualiseren van de gebruikte datasets. Creeër daarnaast een bestand `model.py` in een code-editor naar keuze en sla al deze bestanden gezamenlijk op in één werkmap. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "**Opmerking:**\n",
    "    \n",
    "Op BlackBoard tref je ook een `*.html` versie van dit notebook aan met daarin de evaluaties van alle onderstaande code. Gebruik deze zonodig als voorbeeld om te zien welke uitvoer zoal gewenst is.\n",
    "\n",
    "</div>\n",
    "\n",
    "We beginnen met het importeren van de functies in de `data` module, samen met de nu nog lege `model` module die je zelf gaat schrijven. Verder laden we alvast enkele ondersteunende functies uit de modules `sklearn` en `pandas` die we later zullen gebruiken, en voeren we wat initialisatie-code uit. Plaats de cursor in de cel hieronder en druk op Ctrl+Enter (of Shift+Enter om meteen naar de volgende cel te gaan).\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "**Opmerking:**\n",
    "    \n",
    "Als het label in de linkermarge verandert van `In [ ]:` via `In [*]:` naar `In [1]:` is de code succesvol uitgevoerd en werkt dit notebook naar behoren.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from sys import version\n",
    "print(f'Using python version {version.split(\" \")[0]}')\n",
    "\n",
    "from pandas import DataFrame, __version__\n",
    "print(f'Using pandas version {__version__}')\n",
    "\n",
    "from sklearn import linear_model, __version__\n",
    "print(f'Using sklearn version {__version__}')\n",
    "\n",
    "import model, data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "**Opmerking:**\n",
    "    \n",
    "Als `pandas` of `sklearn` niet geinstalleerd is op je systeem, voer dan `pip3 install pandas sklearn` uit in een terminal en herstart de python kernel via de menu-optie `Kernel` > `Restart` van dit notebook.\n",
    "\n",
    "</div>\n",
    "\n",
    "Laten we eerst eens beter kijken naar de dataset die we in dit werkcollege gaan gebruiken. De functie `data.linear()` produceert een verzameling willekeurige instances met numerieke attributen. Er zijn onder andere parameters om het aantal instances en het aantal attributen te bepalen. Al deze parameters hebben geschikte default waarden. Een verplichte string parameter geeft aan of de dataset discrete uitkomsten dient te hebben t.b.v. classificatie (`outcome='nominal'`) of continue uitkomsten t.b.v. regressie (`outcome='numeric'`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(data.linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De functie retourneert een geneste lijst met vectoren die de attributen van de instances bevat en een enkelvoudige lijst met klasselabels danwel getalwaarden die de bijbehorende uitkomsten bevat. De nominale data zijn lineair separabel; de continue data volgen een exacte lineaire relatie. De algoritmen die we in dit werkcollege implementeren zouden hierdoor in principe in staat behoren te zijn deze data *perfect* te modelleren.\n",
    "\n",
    "### <a id='Het_perceptron'>Het perceptron</a>\n",
    "\n",
    "Laten we beginnen met een dataset met twee attributen $(x_1, x_2)$ en met nominale klasselabels $y$ waarop we classificatie kunnen toepassen d.m.v. het perceptron. De eerste vijf instances worden hieronder weergegeven in tabelvorm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = data.linear('nominal')\n",
    "DataFrame(xs, columns=['x1', 'x2']).assign(y=ys).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verken zelf nader de structuur van de `xs` en `ys` variabelen: wat voor type variabelen zijn het, hoe lang zijn de lijsten, en zo verder.\n",
    "\n",
    "De functie `data.scatter()` geeft de instances van beide klassen weer middels een kleurcode (rood voor de klasse $y=-1$ en blauw voor de klasse $y=+1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.scatter(xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definieer nu een `Perceptron()` class in het bestand `model.py` met aanvankelijk alleen de onderstaande `__repr__()` methode die een textuele representatie geeft van het object:\n",
    "\n",
    "```python\n",
    "class Perceptron():\n",
    "\n",
    "    def __repr__(self):\n",
    "\t\ttext = f'Perceptron(dim={self.dim})'\n",
    "\t\treturn text\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "**Opmerking:**\n",
    "    \n",
    "Vergeet niet om tijdens het uitwerken van deze oefening je aanpassingen in de editor telkens op te slaan voordat je de code in dit notebook uitvoert.\n",
    "    \n",
    "</div>\n",
    " \n",
    "We beginnen met het implementeren van de initialisatie-methode `__init__()`. Deze krijgt één verplichte parameter `dim` die aangeeft hoeveel attributen de te classificeren instances zullen hebben. Verder dienen er twee instance-variabelen te worden geïnitialiseerd: `bias` met de bias $b$ en `weights` met de gewichten $\\boldsymbol{w}$; de methode dient deze zelf van geschikte beginwaarden te voorzien.\n",
    "\n",
    "Het resultaat is iets als:\n",
    "\n",
    "```python\n",
    "    def __init__(self, dim):\n",
    "        self.dim = ...\n",
    "        self.bias = ...\n",
    "        self.weights = ...\n",
    "```\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Opmerking:**\n",
    "    \n",
    "Voorzie je eigen code waar nodig van documentatie en commentaren, evenals desgewenst assertions en foutafhandeling. In de voorbeelden in deze notebooks worden deze niet getoond omwille van bondigheid, maar het gebruik hiervan wordt desalniettemin aangeraden.\n",
    "\n",
    "</div>\n",
    "\n",
    "Als het goed is kun je nu zonder foutmeldingen een nieuw eigen `Perceptron()` object instantiëren en weergeven met de volgende code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_perceptron = model.Perceptron(dim=2)\n",
    "print(my_perceptron)\n",
    "print(f'- bias = {my_perceptron.bias}')\n",
    "print(f'- weights = {my_perceptron.weights}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De volgende stap is om de code te schrijven die voor een gegeven instance een voorspelling kan doen van het juiste klasselabel op grond van het model van het perceptron:\n",
    "\n",
    "$$\n",
    "\\hat{y}=\\text{sgn}\\left(b+\\sum_{i}w_{i}\\cdot x_{i}\\right)\n",
    "$$\n",
    "\n",
    "Creeër een methode `predict(self, xs)` met een parameter `xs` die de attributen van een lijst instances ontvangt. Deze methode dient een lijst waarden te retourneren die overeenkomen met de uitkomsten van de bovenstaande formule. De invoer van deze functie is dus een geneste lijst van lijsten; de uitvoer is een enkelvoudige lijst.\n",
    "\n",
    "Als je deze code correct hebt geïmplementeerd kunnen we het model vragen om een voorspelling te doen omtrent de labels van de beschikbare data. Omdat het perceptron nog niet getraind is is de voorspelling $\\hat{y}$ overal gelijk aan nul. Als je hieronder geen foutmeldingen krijgt dan functioneert je predictie-methode vooralsnog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_perceptron = model.Perceptron(dim=2)\n",
    "yhats = my_perceptron.predict(xs)\n",
    "DataFrame(xs, columns=['x1', 'x2']).assign(y=ys, ŷ=yhats).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vervolgens gaan we het perceptron trainen op grond van instances met gegeven attributen en klasselabels. Pas hiervoor met de aangeleverde instances één voor één de update-regel toe:\n",
    "\n",
    "$$\n",
    "\\left\\{ \\begin{array}{c}\n",
    "b\\leftarrow b-\\left(\\hat{y}-y\\right)\\\\\n",
    "w_{i}\\leftarrow w_{i}-\\left(\\hat{y}-y\\right)x_{i}\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "Voeg een methode `partial_fit()` toe aan je perceptron met parameters die de attributen en klasselabels van een aantal trainingsinstances ontvangt. Het resultaat is iets als:\n",
    "\n",
    "```python\n",
    "    def partial_fit(self, xs, ys):\n",
    "        for x, y in zip(xs, ys):\n",
    "            ...   # Update hier het perceptron met één instance {x, y}\n",
    "```\n",
    "\n",
    "De methode dient elke instance één maal te gebruiken om een update uit te voeren; er wordt dus één epoch getraind met de gegeven data. Deze functie hoeft niets te retourneren.\n",
    "\n",
    "Als je deze code correct hebt geïmplementeerd zou je hieronder een gekleurde achtergrond moeten zien die weergeeft hoe het perceptron de verschillende waarden van de attributen zou classificeren nadat het éénmaal getraind is op de eerste vijf instances uit de dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_perceptron = model.Perceptron(dim=2)\n",
    "my_perceptron.partial_fit(xs[:5], ys[:5])\n",
    "data.scatter(xs, ys, model=my_perceptron)\n",
    "print(my_perceptron)\n",
    "print(f'- bias = {my_perceptron.bias}')\n",
    "print(f'- weights = {my_perceptron.weights}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hoogstwaarschijnlijk zal er nog geen correcte grenslijn gevonden worden, maar het perceptron doet wel al een aantal juiste voorspellingen en je zou moeten kunnen zien dat de bias en gewichten zijn bijgewerkt.\n",
    "\n",
    "Voeg tenslotte een methode `fit(self, xs, ys, *, epochs=0)` toe die meerdere epochs uitvoert, zoals opgegeven door de gebruiker. Maak hierbij gebruik van de eerdere `partial_fit()` functie om telkens één hele epoch te trainen. Zorg dat het perceptron automatisch stopt met het draaien van verdere epochs als er in de vorige epoch geen veranderingen in het model meer zijn aangebracht. Als de gebruiker om nul epochs verzoekt (of geen waarde meegeeft waardoor de default waarde `epochs=0` geldt), laat dan het algoritme zoveel epochs draaien als maar nodig zijn om te convergeren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_perceptron = model.Perceptron(dim=2)\n",
    "my_perceptron.fit(xs, ys)\n",
    "data.scatter(xs, ys, model=my_perceptron)\n",
    "print(my_perceptron)\n",
    "print(f'- bias = {my_perceptron.bias}')\n",
    "print(f'- weights = {my_perceptron.weights}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rosenblatt heeft bewezen dat het perceptron algoritme gegarandeerd in een eindig aantal stappen convergeert naar een oplossing die alle instances juist classificeert als de data lineair separabel zijn. Dat is hier het geval. Als je dit juist implementeert zou de bovenstaande code daarom een lijn moeten vinden die de beide klassen perfect van elkaar weet te scheiden.\n",
    "\n",
    "Hieronder worden de eerste vijf instances in een tabel getoond; ga na dat de voorspelling $\\hat{y}$ telkens precies gelijk is aan het echte klasselabel $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhats = my_perceptron.predict(xs)\n",
    "DataFrame(xs, columns=['x1', 'x2']).assign(y=ys, ŷ=yhats).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "**Gefeliciteerd!**\n",
    "    \n",
    "Je hebt nu zelf een algoritme geïmplementeerd dat een lineair separabele verzameling trainingsdata perfect kan leren onderscheiden.\n",
    "\n",
    "</div>\n",
    "\n",
    "Ter vergelijking tonen we hieronder het perceptron zoals dit in de machine-learning module [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Perceptron.html) reeds beschikbaar is. De syntax van deze class is zeer vergelijkbaar met de onze, hoewel de bias en coefficienten beschikbaar zijn in de `intercept_` en `coef_` variabelen, en een parameter `max_iter` het gewenste (maximum) aantal epochs aangeeft.\n",
    "\n",
    "Ziet de oplossing er hetzelfde uit als voor je eigen model? Ga na dat de waarden van de bias en de gewichten niet van dezelfde grootten zijn. Begrijp je hoe dit toch ogenschijnlijk hetzelfde model kan opleveren?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_perceptron = linear_model.Perceptron(max_iter=1000)\n",
    "skl_perceptron.fit(xs, ys)\n",
    "data.scatter(xs, ys, model=skl_perceptron)\n",
    "print(skl_perceptron)\n",
    "print(f'- bias = {skl_perceptron.intercept_[0]}')\n",
    "print(f'- weights = {skl_perceptron.coef_[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='Lineaire_regressie'>Lineaire regressie</a>\n",
    "\n",
    "Vervolgens doen we hetzelfde met instances die een getalwaarde als te voorspellen uitkomst hebben. Eerst maar weer eens een kijkje nemen naar de data. De uitkomsten $y$ zijn nu numeriek, dat wil zeggen kommagetallen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, ys = data.linear('numeric')\n",
    "DataFrame(xs, columns=['x1', 'x2']).assign(y=ys).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De instances worden nu gekleurd langs het hele bereik van de kleurschaal. De ligging van de verschillende kleuren in het scatterplot vormt een zichtbare geleidelijke overgang van rood via geel naar blauw."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.scatter(xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kopieer de code van het perceptron om een nieuwe class `LinearRegression()` toe te voegen aan hetzelfde bestand `model.py` en pas de initialisatie-, representatie- en predictie-methoden aan. Het model voor lineaire regressie luidt:\n",
    "\n",
    "$$\n",
    "\\hat{y}=b+\\sum_{i}w_{i}\\cdot x_{i}\n",
    "$$\n",
    "\n",
    "De methode `predict(self, xs)` dient in dit geval een lijst met getalwaarden te retourneren i.p.v. een lijst met klasselabels.\n",
    "\n",
    "Een ongetraind model zou wederom uitkomsten gelijk aan nul moeten voorspellen. Controleer dat je geen foutmeldingen krijgt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_linearregression = model.LinearRegression(dim=2)\n",
    "yhats = my_linearregression.predict(xs)\n",
    "DataFrame(xs, columns=['x1', 'x2']).assign(y=ys, ŷ=yhats).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vervolgens gaan we het lineaire regressiemodel trainen, eerst weer op grond van de eerste vijf instances met de update-regel:\n",
    "\n",
    "$$\n",
    "\\left\\{ \\begin{array}{c}\n",
    "b\\leftarrow b-\\alpha\\left(\\hat{y}-y\\right)\\\\\n",
    "w_{i}\\leftarrow w_{i}-\\alpha\\left(\\hat{y}-y\\right)x_{i}\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "De methode `partial_fit(self, xs, ys, *, alpha=...)` krijgt nu een extra parameter, de learning rate $\\alpha$. Geef deze een geschikte default waarde."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_linearregression = model.LinearRegression(dim=2)\n",
    "my_linearregression.partial_fit(xs[:5], ys[:5])\n",
    "data.scatter(xs, ys, model=my_linearregression)\n",
    "print(my_linearregression)\n",
    "print(f'- bias = {my_linearregression.bias}')\n",
    "print(f'- weights = {my_linearregression.weights}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na het trainen met enkele instances zou er al een zwakke gradiënt in de achtergrond zichtbaar kunnen worden. De diagonale stippellijn geeft hierboven aan waar de voorspelling $\\hat{y}=0$; deze scheidt dus de instances met een voorspelde positieve uitkomst van die met een voorspelde negatieve uitkomst.\n",
    "\n",
    "Voeg nu tenslotte weer de methode `fit(self, xs, ys, *, alpha=..., epochs=...)` toe die training toepast op een gegeven aantal hele epochs. Pas de default waarde voor de learning rate weer aan, in overeenstemming met de functie `partial_fit()`. In tegenstelling tot bij het perceptron kan het aantal epochs nu niet default op nul worden gesteld, met als betekenis dat het algoritme door dient te itereren tot alle instances juist geclassificeerd zijn. Immers, het lineaire regressie model convergeert meestal niet in een eindig aantal stappen naar een exacte uitkomst. Wel wordt er bij een juiste keuze van $\\alpha$ geleidelijk een steeds betere benadering gevonden. Vandaar dat we hier standaard een redelijk groot aantal epochs willen uitvoeren. Kies wederom zelf een geschikte default waarde.\n",
    "\n",
    "Draai de code hieronder. Slaagt je model erin om te convergeren naar een uitkomst die de echte getalwaarden van de instances ogenschijnlijk goed voorspelt? Hoe kun je dit zien?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_linearregression = model.LinearRegression(dim=2)\n",
    "my_linearregression.fit(xs, ys)\n",
    "data.scatter(xs, ys, model=my_linearregression)\n",
    "print(my_linearregression)\n",
    "print(f'- bias = {my_linearregression.bias}')\n",
    "print(f'- weights = {my_linearregression.weights}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controleer hieronder dat de voorspellingen inderdaad goed overeen komen met de gewenste waarden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhats = my_linearregression.predict(xs)\n",
    "DataFrame(xs, columns=['x1', 'x2']).assign(y=ys, ŷ=yhats).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "**Gefeliciteerd!**\n",
    "    \n",
    "Je hebt nu ook een algoritme geïmplementeerd dat lineaire regressie kan uitvoeren.\n",
    "\n",
    "</div>\n",
    "\n",
    "Ter vergelijking tonen we hieronder ook weer het lineaire regressiemodel uit de machine-learning module [scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html). Bekijk de syntax van deze functie. De bias en coefficienten zijn opnieuw toegankelijk via de `intercept_` en `coef_` variabelen.\n",
    "\n",
    "Ziet de oplossing er dit keer hetzelfde uit als voor je eigen model? Zijn de waarden van de bias en de gewichten nu wel van vergelijkbare grootten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skl_linearregression = linear_model.LinearRegression()\n",
    "skl_linearregression.fit(xs, ys)\n",
    "data.scatter(xs, ys, model=skl_linearregression)\n",
    "print(skl_linearregression)\n",
    "print(f'- bias = {skl_linearregression.intercept_}')\n",
    "print(f'- weights = {skl_linearregression.coef_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "<small>&copy; 2024, Dave R.M. Langers, [d.r.m.langers@pl.hanze.nl](mailto:d.r.m.langers@pl.hanze.nl)</small>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
